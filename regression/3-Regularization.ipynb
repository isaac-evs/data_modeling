{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881e99ee-d8a7-4ac2-9587-e6db839c304c",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://i0.wp.com/laid.delanover.com/wp-content/uploads/2018/01/reg_formulas.png?w=550&ssl=1\" width=\"350px\" height=\"480px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- \n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://i0.wp.com/laid.delanover.com/wp-content/uploads/2018/01/reg_formulas.png?w=550&ssl=1</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Regularización</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f922e-d509-4bfe-a8a1-c1d929543da0",
   "metadata": {},
   "source": [
    "## Ejemplo: predecir la progresión de la enfermedad en la diabetes\n",
    "\n",
    "Este conjunto de datos contiene 10 características, como edad, sexo, índice de masa corporal (IMC), presión arterial y varias mediciones del suero sanguíneo, que se utilizan para predecir una medida cuantitativa de la progresión de la enfermedad un año después del inicio.\n",
    "\n",
    "Aplicaremos tres técnicas de regularización (Ridge (L2), Lasso (L1) y Elastic Net (una combinación de L1 y L2) a un modelo de regresión lineal y compararemos su rendimiento.\n",
    "\n",
    "**Nota:** Aunque la progresión real de la diabetes se rige por complejos procesos biológicos no lineales, aquí utilizamos intencionalmente modelos lineales para mayor claridad. La regresión lineal nos permite demostrar claramente los efectos de la regularización en el sobreajuste, la reducción de coeficientes y la selección de características. Los modelos más avanzados, pueden producir una mayor precisión, pero a menudo dificultan la interpretación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b689751-500c-49f7-84f6-f30fab955cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32662f-eb79-4713-9d44-2d7f023ce5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a8285-c6f2-41e5-92ca-cb8bfa962d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X,y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4a310-6ee1-4124-b2ba-1397b559d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0a47c-012d-4e4a-b0bd-f34b172755a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557fe37-5437-4414-ba5f-fe05bec1ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(X_train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d86f2-3514-4e66-a085-9f8e2dbda374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los modelos y el grid de hiperparametros a probar\n",
    "models = {\n",
    "    \"Ridge\": (Ridge(), {\"alpha\": [0.01, 0.1, 1, 10, 100]}),\n",
    "    \"Lasso\": (Lasso(max_iter=10000), {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1]}),\n",
    "    \"ElasticNet\": (\n",
    "        ElasticNet(max_iter=10000),\n",
    "        {\"alpha\": [0.0001, 0.001, 0.01, 0.1], \"l1_ratio\": [0.1, 0.5, 0.9]}\n",
    "    )\n",
    "}\n",
    "# Aplicamos grid search para buscar los hiperparámetros optimos\n",
    "results = []\n",
    "coefs = {}\n",
    "\n",
    "for name, (model, param_grid) in models.items():\n",
    "    search = GridSearchCV(model, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\")\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    non_zero = np.sum(best_model.coef_ != 0)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Mejores hiperparametros\": search.best_params_,\n",
    "        \"Test RMSE\": round(rmse, 4),\n",
    "        \"Test R²\": round(r2, 4),\n",
    "        \"Test MAE\": round(mae, 4),\n",
    "        \"Coeficientes que no son cero\": non_zero\n",
    "    })\n",
    "    coefs[name] = best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84b50c-a9de-4d0e-9fd1-29e44ec276f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver resultados de comparacion de modelos\n",
    "results_df = pd.DataFrame(results)\n",
    "coefs_df = pd.DataFrame(coefs)\n",
    "coefs_df[\"Feature\"] = feature_names.values\n",
    "print(\"Comparar modelos:\\n\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e0d3f-e332-4246-8d8a-e44dd1dfd504",
   "metadata": {},
   "source": [
    "Aunque los tres modelos obtuvieron un rendimiento similar en términos de RMSE, MAE y R², Lasso superó ligeramente a los demás en ambas métricas. \n",
    "\n",
    "Es importante destacar que Lasso redujo la cantidad de variables de 10 a 7, lo que demuestra su capacidad para realizar la selección de variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f5752-6994-4d46-80a5-63da35cd5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCoeficientes por modelo:\\n\", coefs_df[[\"Feature\", \"Ridge\", \"Lasso\", \"ElasticNet\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2d177-ea4a-478b-af57-0ea78d536209",
   "metadata": {},
   "source": [
    "#### La regularización siempre es mejor???\n",
    "\n",
    "\n",
    "#### Cuándo usar cada uno?\n",
    "\n",
    "- Ridge es ideal cuando deseas reducir el sobreajuste manteniendo todas las variables. Funciona bien cuando todas las variables son importantes pero potencialmente relacionadas.\n",
    "- Lasso es poderosa cuando la selección de variables es una prioridad. Elimina por completo las características menos útiles al reducir sus coeficientes a cero.\n",
    "- ElasticNet combina ambos enfoques. Es útil cuando sospechas que hay correlaciones entre variables y aún desea algo de reducción de variables.\n",
    "\n",
    "#### Cuándo aplicar la regularización?\n",
    "\n",
    "- Tienes una gran cantidad de variables o multicolinealidad potencial.\n",
    "- Tu modelo se está sobreajustando a los datos de entrenamiento\n",
    "- Necesitas un modelo más simple e interpretable\n",
    "\n",
    "#### Proceso recomendado:\n",
    "1. Comienza con Ridge (L2) si tu objetivo es la estabilidad y no estás tan seguro de eliminar características.\n",
    "2. Prueba Lasso (L1) si sospecha que muchas variables son irrelevantes y desea una selección automática de variables.\n",
    "3. Utiliza ElasticNet si necesitas un equilibrio entre reducción de variables y estabilidad, especialmente cuando las variables están correlacionadas.\n",
    "4. Ajusta los hiperparámetros mediante cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
