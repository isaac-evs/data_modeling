{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://http2.mlstatic.com/D_NQ_NP_2X_960089-MLM26807621582_022018-F.webp\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Selección de Variables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selección de variables es un proceso donde automáticamente se seleccionan aquellos atributos en nuestros datos que contribuyen más a la variable a predecir. \n",
    "\n",
    "Las variables irrelevantes o parcialmente relevantes pueden afectar negativamente el rendimiento del modelo.\n",
    "\n",
    "Beneficios:\n",
    "- Reducir sobreajuste: menos datos irrelevantes significan menos oportunidades de tomar decisiones basadas en ruido = mejor performance. \n",
    "- Modelo más fácil de entender\n",
    "- Reduce el tiempo de entrenamiento: menos datos significa que el modelo se entrena más rápido\n",
    "\n",
    "\n",
    "**Tipos de algoritmos de selección de variables**\n",
    "\n",
    "    - **Métodos de envoltura (wrapper)**: se considera como un problema de búsqueda la selección de un conjunto de variables donde diferentes combinaciones se preparan, evalúan y comparan con otras combinaciones. Se utiliza un modelo predictivo para evaluar una combinación de características y asignar un score basado en la precisión del modelo. \n",
    "        - Ejemplo: RFE\n",
    "\n",
    "    - **Métodos de filtrado**: estos métodos aplican una medida estadística para asignar una puntuación a cada característica. Las características se clasifican según la puntuación y se seleccionan para conservarlas o eliminarlas del conjunto de datos. Los métodos suelen ser univariados y consideran la característica de forma independiente o con respecto a la variable dependiente.\n",
    "        - Ejemplo: prueba de chi cuadrada, L-Anova, método de correlación, criterio de la varianza\n",
    "\n",
    "    - **Métodos embebidos (intrinsecos)**: mientras se va creando el modelo el método aprende qué características contribuyen mejor a la precisión. El método más común es el de regularización. \n",
    "        - Ejemplo: LASSO, Elastic Net, Ridge, Trees\n",
    "\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/11/Overview-of-Feature-Selection-Techniques3.png\" width=\"550\" height=\"480\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mencionando algunas técnicas más comunes:**\n",
    "\n",
    "- Porcentaje de valores nulos\n",
    "- Cantidad de variación\n",
    "- Correlación por parejas\n",
    "- Mulicolinealidad\n",
    "- PCA\n",
    "- Correlación con la variable a predecir (target)\n",
    "- Forward Selection\n",
    "- Backward Selection\n",
    "- Stepwise Selection\n",
    "- LASSO\n",
    "- Selección basada en árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo elegir las mejores variables?**\n",
    "No es una respuesta fácil, hay que tratar de varias formas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos: Cáncer de mama\n",
    "Los datos se pueden encontrar en:\n",
    "https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "\n",
    "Se busca clasificar qué si un tumor es maligno (1) o benigno (0). \n",
    "\n",
    "Se tiene información de 30 variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "df = pd.concat([X,y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vistazo datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estadistica de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos la variable de salida\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué tipos de datos tenemos aquí?** \n",
    "\n",
    "Las variables de entrada (independientes) son: \n",
    "\n",
    "La variable de salida (dependiente) es: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= #2E9AFE> Paso 1</font>\n",
    "\n",
    "**Comienzamos por comprender el negocio**\n",
    "\n",
    "- Hablar con los expertos en la materia\n",
    "\n",
    "- Comprende qué características deberían ser importantes según el problema\n",
    "\n",
    "- Elimina las variables obvias sin sentido (p. ej., identificadores, variables sin valor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= #2E9AFE> Paso 2</font>\n",
    "\n",
    "**Limpieza previa a los datos (solo si es necesario)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamiento --> SOLO A LAS VARIABLES DE ENTRADA\n",
    "x_scaled = X\n",
    "x_scaled =  (x_scaled - x_scaled.mean())/(x_scaled.std())\n",
    "df_scaled = pd.concat([x_scaled,y], axis=1)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= #2E9AFE> Paso 3 Visualización y Cuestionamiento</font>\n",
    "\n",
    "La visualizacion nos ayuda a darnos una idea de qué variables podrían ayudar o no al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violin_plot(beginning,end):\n",
    "    data = pd.concat([y,x_scaled.iloc[:,beginning:end]],axis=1)\n",
    "    data = pd.melt(data, id_vars=\"target\", var_name=\"features\", value_name='value')\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.violinplot(x=\"features\", y=\"value\", hue=\"target\", data=data, split=True, inner=\"quart\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "violin_plot(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean radius, mean perimeter, mean area, compactness mean, mean concavity, mean concave points están bien separados entre tumores malignos y benignos. Estas 6 características serían buenas candidatas para el modelo.\n",
    "\n",
    "Por el contrario, mean fractal dimension tiene la misma mediana para ambos tipos de tumores, por lo que no sería un buen candidato para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plot(20,31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico anterior, notamos algunas similitudes entre el wort radius y el worst perimeter. Si dos violines se parecen, podría indicar una correlación entre las características, y si dos características están correlacionadas, uno puede preguntarse si es posible (o no) eliminar una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data = x_scaled, x = \"worst radius\", y=\"worst perimeter\", color=\"#ce1414\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(18, 18))\n",
    "sns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Con este análisis me atrevería a sugerir remover las siguientes variables:\n",
    " \n",
    " - mean radius\n",
    " - mean perimeter\n",
    "   \n",
    " - mean compactness\n",
    " - mean concave points\n",
    "\n",
    "- radius error\n",
    "- perimeter error\n",
    "\n",
    "- worst radius\n",
    "- worst perimeter\n",
    "\n",
    "- compactness error\n",
    "- concave points error\n",
    "\n",
    "- mean compactness\n",
    "- mean concave points\n",
    "\n",
    "- worst textrue\n",
    "\n",
    "- worst area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** no lo voy a hacer por lo pronto, porque podría remover alguna variable que es estadísticamente significativa para el target (tumor maligno o benigno), así que primero aplicaré un método de filtrado y luego removeré las variables que están muy correlacionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= #2E9AFE> Métodos de Filtrado (si contamos con muchas variables)</font>\n",
    "\n",
    "Si estamos comenzando con la evaluación del dataset. Podríamos iniciar con métodos de filtrado para tomar en cuenta qué variables podríamos remover ya que tenemos muchas variables en nuestros datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# ANOVA\n",
    "selector = SelectKBest(score_func=f_classif, k='all')\n",
    "f_vals, p_vals = f_classif(x_scaled, y)\n",
    "significant = np.where(p_vals < 0.05)[0]\n",
    "print(\"Variables significantes:\", X.columns[significant].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos aquellas variables que son significativas\n",
    "df_reduced = df_scaled[['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(18, 18))\n",
    "sns.heatmap(df_reduced.drop(columns='target').corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opcional**\n",
    "\n",
    "Observo que quedaron todavía variables muy correlacionadas, por lo tanto ahora sí quitaré las variables correlacionadas que vimos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['mean perimeter','mean radius','mean compactness','mean concave points','radius error','perimeter error',\n",
    "             'worst radius','worst perimeter','worst compactness','worst concave points',\n",
    "             'compactness error','concave points error','worst texture','worst area']\n",
    "df_reduced = df_reduced.drop(drop_list,axis = 1 )\n",
    "df_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso sería aplicar una selección de variables dirigida al modelo. \n",
    "\n",
    "Podemos usar\n",
    "\n",
    "- Wrapper methods: si tenemos modeos como regresión logística, regresión lineal o máquinas de vector soporte\n",
    "- Métodos embebidos: si vamos a utilizar algún modelo en específico que ya tenga dentro del modelo un método de selección de variables\n",
    "\n",
    "\n",
    "# <font color= #2E9AFE> Métodos de Envoltura (Wrapper)</font>\n",
    "\n",
    "### Eliminación Recursiva de Características (RFE)\n",
    "\n",
    "Funciona eliminando atributos de forma recursiva y construyendo un modelo sobre los atributos que quedan.\n",
    "\n",
    "Usa la precisión del modelo para identificar qué atributos (y combinación de atributos) contribuyen más a predecir el objetivo.\n",
    "\n",
    "Vamos a utilizar la regresión logística para seleccionar las características principales. \n",
    "\n",
    "**Por lo general se usa dentro del cross-validation o en pipelines para evitar el overfitting** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "selector = RFECV(LogisticRegression(max_iter = 10000), cv=5)\n",
    "\n",
    "X = df_reduced.drop(columns=\"target\")\n",
    "y = df_reduced['target']\n",
    "selector.fit(X,y)\n",
    "X_selected = X.loc[:, selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= #2E9AFE> Métodos embebidos (intrínsecos)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen algunos modelos (vamos a irlos viendo) que dentro de su construcción ya hacen una selección de variables. Uno de ellos son los modelos basados en árboles como el \"Random Forest\". \n",
    "\n",
    "Construimos un Clasificador de \"Random Forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#creamos el modelo del random forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Vamos a quedarnos con las variables que tengan una importancia arriba del promedio\n",
    "sfm = SelectFromModel(rf, threshold='median')\n",
    "sfm.fit(X, y)\n",
    "X_embedded = X.loc[:, sfm.get_support()]\n",
    "print(\"Variables seleccionadas metodo embebido dentro del random forest:\", X_embedded.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos la importancia de las variables\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_names[sorted_idx], importances[sorted_idx])\n",
    "plt.title(\"Feature Importances (Random Forest)\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando el performance de los modelos utilizando los distintos métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def evaluate_model(X_subset, y, model):\n",
    "    scores = cross_val_score(model, X_subset, y, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "print(\"Método de filtrado:\", evaluate_model(df_reduced.drop(columns=\"target\"), y, LogisticRegression(max_iter=10000)))\n",
    "print(\"Método Wrapper (RFECV):\", evaluate_model(X_selected, y, LogisticRegression(max_iter=10000)))\n",
    "print(\"Método embebido (Random Forest):\", evaluate_model(X_embedded, y, RandomForestClassifier(random_state=42)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuantas variables eligió cada método\n",
    "print(\"Metodo filtrado:\", df_reduced.drop(columns=\"target\").shape[1])\n",
    "print(\"Metodo wrapper:\", X_selected.shape[1])\n",
    "print(\"Metodo embebido:\", X_embedded.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es el mejor método?\n",
    "\n",
    "...no hay...\n",
    "\n",
    "Se tiene que hacer experimentación para ver qué método funciona mejor para el problema en específico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "La cantidad ideal de variables NO siempre es la menor: hay que observar el rendimiento del modelo, la interpretabilidad y las necesidades del negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:\n",
    "\n",
    "- https://www.stratascratch.com/blog/feature-selection-techniques-in-machine-learning/\n",
    "- https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py\n",
    "- https://scikit-learn.org/stable/modules/feature_selection.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Sara E. Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
