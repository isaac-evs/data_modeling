{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815ba06e-6501-4f93-b31a-f23272475cfc",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://docs.aws.amazon.com/images/machine-learning/latest/dg/images/mlconcepts_image5.png\" width=\"450px\" height=\"280px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "## <font color= #2E9AFE> Tema: Overfitting y Underfitting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d9e87e-55bd-4be1-98c1-5a6d8fa96a7b",
   "metadata": {},
   "source": [
    "| Término    | Significado | Síntomas |\n",
    "| -------- | ------- | ------- |\n",
    "| Underfitting  |Modelo es demasiado simple para aprender patrones.    | Bajo performance tanto en entrenamiento y prueba    |\n",
    "| Overfitting | El modelo es demasiado complejo, se memoriza los datos de entrenamiento     |  Exactitud en el entrenamiento alto, Exactitud en la prueba mucho más baja    |\n",
    "| Balanceado    | El modelo captura los patrones y se generaliza bien    | Exactitud alta en entrenamiento y prueba, la curva de aprendizaje converge    |\n",
    "\n",
    "\n",
    "#### <font color= #2E9AFE> Underfitting</font>\n",
    "\n",
    "**Cómo se puede corregir?**\n",
    "- Agregar más variables: crear nuevas variables o combinar algunas existentes para que el modelo capture más patrones\n",
    "- Quitar variables redundantes\n",
    "- Reducir la regularización\n",
    "- Usar un modelo más complejo\n",
    "- Probar con variables polinómicas (si es posible)\n",
    "\n",
    "\n",
    "#### <font color= #2E9AFE> Overfitting</font>\n",
    "\n",
    "**Cómo se puede corregir?**\n",
    "- Agregar más datos que den más variedad de ejemplos (no siempre es posible)\n",
    "- Reducir la complejidad del modelo (ej. elegir un modelo más sencillo o elegir hiperparámetros menos complejos)\n",
    "- Agregar regularización (L1/L2)\n",
    "- Usar cross-validation para tunear hiperparámetros\n",
    "- Usar el \"early stopping\" para modelos iterativos (ej. redes neuronales)\n",
    "\n",
    "\n",
    "#### <font color= #2E9AFE> Ajuste balanceado</font>\n",
    "\n",
    "**Cómo lo obtenemos?**\n",
    "- Pre-procesamiento adecuado (limpieza, escalamiento, imputacion, etc)\n",
    "- Buena elección del modelo\n",
    "- Buen ajuste de hiperparámetros\n",
    "- Cross validation\n",
    "\n",
    "#### <font color= #2E9AFE> Cómo lo detectamos?</font>\n",
    "- Calcular métricas de performance tanto en el train como en el test\n",
    "- Curvas de aprendizaje\n",
    "- Performance en el cross validation\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Bias and Variance Trade Off</font>\n",
    "\n",
    "Una de las grandes tensiones que existe al crear un modelo de machine learning es que queremos **construir un modelo que sea lo suficientemente expresivo como para capturar los patrones en los datos, pero no tan flexible como para confundir ruido con señal.**\n",
    "\n",
    "Para cuantificar el rendimiento del modelo, a menudo analizamos el error cuadrático esperado entre la predicción del modelo y la verdadera función que pretendemos aproximar. Este error esperado se puede dividir en tres componentes:\n",
    "\n",
    "$$Total Error = Bias^{2} + Variance + Irreducible Error$$\n",
    "\n",
    "**Bias (o sesgo):** error que ocurre al aproximar un problema complejo del mundo real con un modelo simplificado. Un sesgo alto indica que el modelo pasa por alto relaciones esenciales en los datos, lo que lleva a un underfitting.\n",
    "\n",
    "**Variance:** Mide qué tan sensible es el modelo a pequeños cambios en los datos de entrenamiento (específicamente, entrada). Un modelo con alta varianza no solo captura el patrón sino también el ruido específico de ese conjunto de datos, lo que genera un rendimiento deficiente con datos nuevos; este fenómeno se conoce como sobreajuste.\n",
    "\n",
    "**Irreducible error:** El error irreducible surge del ruido inherente al proceso y no puede ser eliminado por ningún modelo. Puede deberse a errores de sensores, inconsistencias en las anotaciones humanas, variables de confusión no medidas o aleatoriedad del sistema.\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://www.kdnuggets.com/wp-content/uploads/arya_biasvariance_tradeoff_4.png\" width=\"600px\" height=\"600px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10f005-8340-41d7-b01d-bf9b213f51cc",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Para estudiar la naturaleza del sobreajuste, vamos a hacer un ejemplo de juguete de polinomios. Más adelante veremos que nuestros hallazgos no son específicos de polinomios y pueden extenderse a otros métodos supervisados de aprendizaje automático, como regresiones lineales, bosques aleatorios, etc.\n",
    "\n",
    "Un polinomio de grado *n* tiene la forma:\n",
    "\n",
    "$$f(x) = w_0 + w_1 \\cdot x + w_2 \\cdot x^2 + ... + w_n \\cdot x^n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e9165-2c34-4a3e-816b-edae212196d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7c2fa-87b1-48c5-a08f-57b8a0dd755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos datos polinomiales dummies con ruido \n",
    "\n",
    "def make_polynomial_data(weight, n_samples=100, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    x = (0.5-np.random.rand(n_samples))*2\n",
    "    x = np.sort(x)\n",
    "    y_true = np.polyval(weight, x)\n",
    "    y = y_true + np.random.randn(n_samples)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "weights = np.array([10, 0, -5, 0])\n",
    "X, y = make_polynomial_data(weights, n_samples=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349b3df-bc98-4a5e-921d-78c3f0f99e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Datos polinomiales')\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ca782-263e-4adc-acdb-85737fe1c424",
   "metadata": {},
   "source": [
    "#### Dividimos los datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3036bb9-4b10-4a60-98ff-75f1c8bfec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0dbc48-7e65-409e-83af-d75ff6b7fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Datos polinomiales')\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.title('Datos polinomiales')\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d7233-1cff-453c-a1f3-b58964ab8d67",
   "metadata": {},
   "source": [
    "Ahora ajustamos un polinomio a los datos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778f8cc-f0e9-4789-821a-5c4205b83127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegressor:\n",
    "    def __init__(self, degree=0, w_hat=None):\n",
    "        self.degree = degree\n",
    "        self.w_hat = w_hat\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"entrenamos el polinomio\"\"\"\n",
    "        self.w_hat = np.polyfit(x, y, self.degree)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"Predecimos\"\"\"\n",
    "        if self.w_hat is not None:\n",
    "            return np.polyval(self.w_hat, x)\n",
    "        else:\n",
    "            raise ValueError('primero necesitas entrenar el modelo.')\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        \"\"\"Evaluamos el modelo\"\"\"\n",
    "        if self.w_hat is not None:\n",
    "            y_hat = np.polyval(self.w_hat, x)\n",
    "            return root_mean_squared_error(y, y_hat)\n",
    "        else:\n",
    "            raise ValueError('primero necesitas entrenar el modelo.')\n",
    "            \n",
    "    def get_params(self, **kwargs):\n",
    "        return {'w_hat': self.w_hat,\n",
    "                'degree': self.degree}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f1a1-a7f4-437b-8dbc-8b66873f046a",
   "metadata": {},
   "source": [
    "#### De underfitting a overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de83838-9306-4bad-951a-dd00646a4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lin = np.linspace(-1, 1, 1000)\n",
    "\n",
    "for degree in [0, 1, 2, 3, 5, 10, 50]:\n",
    "    pr = PolynomialRegressor(degree=degree)\n",
    "    pr.fit(X_train, y_train)\n",
    "    y_fit = pr.predict(X_lin)\n",
    "    \n",
    "    title = f'Polynomial fit degree={degree}'\n",
    "\n",
    "    plt.title('Datos polinomiales')\n",
    "    plt.scatter(X_train, y_train)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.title('Datos polinomiales')\n",
    "    plt.scatter(X_test, y_test)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.plot(X_lin, y_fit, label='fit', c='black')\n",
    "    \n",
    "    plt.ylim([-6, 6])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9c0e3-d78f-4bb5-a083-be154a58ec5e",
   "metadata": {},
   "source": [
    "#### Observamos el error tanto en los datos de entrenamiento como en los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034702f-1925-4e7a-a7ff-aeb654fa98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = []\n",
    "rmse_test = []\n",
    "degrees = list(range(0, 30))\n",
    "\n",
    "for degree in degrees:\n",
    "    pr = PolynomialRegressor(degree=int(degree))\n",
    "    pr.fit(X_train, y_train)\n",
    "    rmse_train.append(pr.evaluate(X_train, y_train))\n",
    "    rmse_test.append(pr.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e151a-b2fe-4f18-9f4f-560ed48baf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees, rmse_train, label='train')\n",
    "plt.plot(degrees, rmse_test, label='test')\n",
    "plt.yscale('linear')\n",
    "plt.title('Curva de aprendizaje')\n",
    "plt.ylabel(\"grado\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923aaad8-8e61-4008-bf68-0ab4ca3a2531",
   "metadata": {},
   "source": [
    "Podemos hacer algunas observaciones:\n",
    "\n",
    "- El error de entrenamiento siempre disminuye al sumar más grados.\n",
    "- Hay una región entre 3 y 15 donde el error de validación es estable y bajo.\n",
    "  \n",
    "Idealmente, elegiríamos los parámetros del modelo de manera que tengamos el mejor rendimiento del modelo. Sin embargo, queremos asegurarnos de que realmente tengamos el mejor rendimiento de validación. Cuando hacemos train_test_split, dividimos aleatoriamente los datos en partes. Lo que podría pasar es que tuvimos suerte y dividimos los datos de manera que favorezca el error de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9d448-9f4b-49c4-b36f-20cc703a612a",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbf6f0-784b-454f-a72e-99ce9eaaaf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = []\n",
    "rmse_valid = []\n",
    "degrees = list(range(0, 16))\n",
    "for degree in degrees:\n",
    "    pr = PolynomialRegressor(degree=degree)\n",
    "    results = cross_validate(pr, X, y,\n",
    "                             cv=5,\n",
    "                             return_train_score=True,\n",
    "                             scoring='neg_root_mean_squared_error')\n",
    "    \n",
    "    rmse_train.append(-np.mean(results['train_score']))\n",
    "    rmse_valid.append(-np.mean(results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9d406-2540-4646-a458-1ab8b77b1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees, rmse_train, label='train')\n",
    "plt.plot(degrees, rmse_valid, label='test')\n",
    "plt.yscale('linear') #log\n",
    "plt.title('Curva de aprendizaje')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"grado\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb2aca-356c-4d44-ba5a-1ce7d4306b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees[np.argmin(rmse_valid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3759c-3a6d-4a4c-b9cf-e0b55dc24022",
   "metadata": {},
   "source": [
    "Estas observaciones no son especiales en cuanto a los polinomios: son válidas para el ajuste de modelos de aprendizaje automático en general. \n",
    "\n",
    "El desafío al adaptar modelos en el aprendizaje automático es encontrar el ajuste adecuado.\n",
    "\n",
    "Un modelo demasiado simple no podrá captar la complejidad de los datos y provocará un underfitting.\n",
    "\n",
    "Un modelo demasiado complejo tiene la capacidad de \"memorizar\" aspectos de los datos y provocar un sobreajuste.\n",
    "\n",
    "Si sobreajustamos nuestro modelo no predecirá bien datos nuevos; decimos que no generaliza.\n",
    "\n",
    "El objetivo es encontrar un modelo que tenga la complejidad adecuada para ajustarse a los datos. El gráfico de tasas de aprendizaje es una herramienta para identificar el punto óptimo de complejidad del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
