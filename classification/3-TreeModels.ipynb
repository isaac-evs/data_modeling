{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640ccd0e-1f94-460b-9d9f-a1499cdfd7e7",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://blog.ekinox.io/images/xgboost_lgbm_catboost.svg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `sara.rodriguezr@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://blog.ekinox.io/images/xgboost_lgbm_catboost.svg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Catboost vs XGBoost vs LightGBM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea5fb2-4cc9-4252-9668-6ebbbcc1024f",
   "metadata": {},
   "source": [
    "## Los Datos (IBM HR)\n",
    "\n",
    "Se busca descubrir los factores que conducen al desgaste de los empleados. Este es un conjunto de datos ficticio creado por científicos de datos de IBM.\n",
    "\n",
    "Variables:\n",
    "- Age\n",
    "- Attrition (target)\n",
    "- BusinessTravel\n",
    "- DailyRate\n",
    "- Department\n",
    "- DistanceFromHome\n",
    "- Education\n",
    "- EducationField\n",
    "- EnvironmentSatisfaction\n",
    "- Gender\n",
    "- HourlyRate\n",
    "- JobInvolvement\n",
    "- JobLevel\n",
    "- JobRole\n",
    "- JobSatisfaction\n",
    "- MaritalStatus\n",
    "- MonthlyIncome\n",
    "- MonthlyRate\n",
    "- NumCompaniesWorked\n",
    "- OverTime\n",
    "- PercentSalaryHike\n",
    "- PerformanceRating\n",
    "- RelationshipSatisfaction\n",
    "- StockOptionLevel\n",
    "- TotalWorkingYears\n",
    "- TrainingTimesLastYear\n",
    "- WorkLifeBalance\n",
    "- YearsAtCompany\n",
    "- YearsInCurrentRole\n",
    "- YearsSinceLastPromotion\n",
    "- YearsWithCurrManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae3262-6703-476e-98b8-fc5b15328b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ddd05-2084-4621-9abc-acc0623b6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt import fmin\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e2a8e-d331-4829-a82e-f85e4b05376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93faaa-d5a4-4423-876a-0ae263a38b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21819777-0aa4-4b37-9cb6-525c9a0db3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2e8af-7049-4384-b625-59395f1ebdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40e5a3-df47-4b85-a97d-14ba3f4cf6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5698ba88-362a-40cd-8f24-35f950890f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = pd.DataFrame(index=['observations(rows)', 'percent missing', 'dtype', 'range'])\n",
    "numerical = []\n",
    "categorical = []\n",
    "for col in df.columns:\n",
    "    obs = df[col].size\n",
    "    p_nan = round(df[col].isna().sum()/obs, 2)\n",
    "    num_nan = f'{p_nan}% ({df[col].isna().sum()}/{obs})'\n",
    "    dtype = 'categorical' if df[col].dtype == object else 'numerical'\n",
    "    numerical.append(col) if dtype == 'numerical' else categorical.append(col)\n",
    "    rng = f'{len(df[col].unique())} labels' if dtype == 'categorical' else f'{df[col].min()}-{df[col].max()}'\n",
    "    description[col] = [obs, num_nan, dtype, rng]\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "display(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34710a46-3eb3-457e-b067-f6b676c67661",
   "metadata": {},
   "source": [
    "**Qué vamos a observar?**\n",
    "\n",
    "- Valores atípicos o inconsistencias en las columnas de datos\n",
    "- ¿Tenemos un desbalanceo en la etiqueta objetivo?\n",
    "- Cómo se distribuyen nuestras variables independientes en relación con nuestra etiqueta objetivo\n",
    "- ¿Hay características que tienen fuertes relaciones lineales o monótonas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b473f8-d07c-4212-9aa6-839f2ec19d72",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535bc377-10ac-4fd0-b29c-16b9b7547a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80dc904-71a6-4786-958f-e2def8282bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distancia de casa vs target\n",
    "df.hvplot.hist(y='DistanceFromHome', by='Attrition', subplots=False, width=600, height=300, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e107ff9-430a-488b-b31d-e54256e25adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educacion vs target\n",
    "df.hvplot.hist(y='Education', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8cb27-b65c-4591-9f90-a659bf299a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Satisfaccion con companieros vs target\n",
    "df.hvplot.hist(y='RelationshipSatisfaction', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7aaf74-5081-4557-990a-c5717d215a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Satisfaccion en la oficina vs target\n",
    "df.hvplot.hist(y='EnvironmentSatisfaction', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8859641-3bdc-4603-8c31-4f8025ed277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Involucramiento laboral vs target\n",
    "df.hvplot.hist(y='JobInvolvement', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcbd13-6e02-44db-b04e-7bd07e5a41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seniority vs target\n",
    "df.hvplot.hist(y='JobLevel', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf3097-11fe-4922-b891-5aaf096942e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Satisfaccion laboral vs target\n",
    "df.hvplot.hist(y='JobSatisfaction', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc36f5-20fb-4628-b60e-99c69ac1f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num companias trabajadas vs target\n",
    "df.hvplot.hist(y='NumCompaniesWorked', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb22ea0-2c1f-400e-ab78-cc89f5be363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aumento salarial vs target\n",
    "df.hvplot.hist(y='PercentSalaryHike', by='Attrition', subplots=False, width=600, height=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091ae26-7b20-4d3e-ae41-169be07b29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acciones en la empresa vs target\n",
    "df.hvplot.hist(y='StockOptionLevel', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb0de1-2310-4846-9e1a-da013e99537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainings en el anio\n",
    "df.hvplot.hist(y='TrainingTimesLastYear', by='Attrition', subplots=False, width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769b684-a27e-4676-9eae-83db00756dcc",
   "metadata": {},
   "source": [
    "Parece que las características EnvironmentSatisfaction, JobSatisfaction, PerformanceRating y RelationshipSatisfaction no tienen un gran impacto en el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f164f-328d-4297-82a9-8335b4436cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edad vs target\n",
    "df.hvplot.hist(y='Age', by='Attrition', subplots=False, width=600, height=300, bins=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8446f8-b691-4a87-a426-f3ff003863ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salario mensual vs target\n",
    "df.hvplot.hist(y='MonthlyIncome', by='Attrition', subplots=False, width=600, height=300, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc83e2-bd1b-4a55-a218-25f00d077705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anios en la compania\n",
    "df.hvplot.hist(y='YearsAtCompany', by='Attrition', subplots=False, width=600, height=300, bins=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2217d6-8e63-48c2-a851-86669e746da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anios totales trabajados\n",
    "df.hvplot.hist(y='TotalWorkingYears', by='Attrition', subplots=False, width=600, height=300, bins=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412445f-dc21-499b-aab7-5bcf725b4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_yes = df.Attrition[df.Attrition == 'Yes'].size\n",
    "count_no = df.Attrition[df.Attrition == 'No'].size\n",
    "\n",
    "plt.bar(['Leave', 'Stay'], [count_yes, count_no])\n",
    "plt.title('Target Imbalance')\n",
    "plt.xlabel('Se fue el empleado?')\n",
    "plt.ylabel('Cuenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037dc256-fd05-491a-9953-9c6200870cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Heatmap(\n",
    "    z = df[numerical].astype(float).corr().values,\n",
    "    x = df[numerical].columns.values,\n",
    "    y = df[numerical].columns.values,\n",
    "    colorscale = 'Portland', \n",
    "    reversescale = False, \n",
    "    opacity = 1.0)\n",
    "        \n",
    "data = [trace1]\n",
    "layout = go.Layout(\n",
    "    title = 'Correlacion',\n",
    "    xaxis = dict(ticks = '', nticks = 36),\n",
    "    yaxis = dict(ticks = ''),\n",
    "    width = 700, height = 700\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5fd20-53bd-4dbc-a6f9-9caf82646739",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c38b1-e126-4b94-b9d6-bdcd86c26887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_results(trials, hyperparams, model_name):\n",
    "    fit_idx = -1\n",
    "    for idx, fit  in enumerate(trials):\n",
    "        hyp = fit['misc']['vals']\n",
    "        xgb_hyp = {key:[val] for key, val in hyperparams.items()}\n",
    "        if hyp == xgb_hyp:\n",
    "            fit_idx = idx\n",
    "            break\n",
    "            \n",
    "    train_time = str(trials[-1]['refresh_time'] - trials[0]['book_time'])\n",
    "    acc = round(trials[fit_idx]['result']['accuracy'], 3)\n",
    "    train_auc = round(trials[fit_idx]['result']['train auc'], 3)\n",
    "    test_auc = round(trials[fit_idx]['result']['test auc'], 3)\n",
    "\n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'parameter search time': train_time,\n",
    "        'accuracy': acc,\n",
    "        'test auc score': test_auc,\n",
    "        'training auc score': train_auc,\n",
    "        'parameters': hyperparams\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c879037-b792-4c3d-bbc5-b727d1498913",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data = df.copy()\n",
    "xgb_dummy = pd.get_dummies(xgb_data[categorical], drop_first=True)\n",
    "xgb_data = pd.concat([xgb_dummy, xgb_data], axis=1)\n",
    "xgb_data.drop(columns = categorical, inplace=True)\n",
    "xgb_data.rename(columns={'Attrition_Yes': 'Attrition'}, inplace=True)\n",
    "\n",
    "y_df = xgb_data['Attrition'].reset_index(drop=True)\n",
    "x_df = xgb_data.drop(columns='Attrition')\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_df, y_df, test_size=0.20)\n",
    "\n",
    "def xgb_objective(space, early_stopping_rounds=50):\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        learning_rate = space['learning_rate'], \n",
    "        n_estimators = int(space['n_estimators']), \n",
    "        max_depth = int(space['max_depth']), \n",
    "        min_child_weight = space['m_child_weight'], \n",
    "        gamma = space['gamma'], \n",
    "        subsample = space['subsample'], \n",
    "        colsample_bytree = space['colsample_bytree'],\n",
    "        objective = 'binary:logistic',\n",
    "        eval_metric = 'auc',\n",
    "        early_stopping_rounds = early_stopping_rounds  # Move here\n",
    "    )\n",
    "    \n",
    "    model.fit(train_x, train_y, \n",
    "              eval_set = [(train_x, train_y), (test_x, test_y)],\n",
    "              verbose = False)\n",
    "     \n",
    "    predictions = model.predict(test_x)\n",
    "    test_preds = model.predict_proba(test_x)[:,1]\n",
    "    train_preds = model.predict_proba(train_x)[:,1]\n",
    "    \n",
    "    xgb_booster = model.get_booster()\n",
    "    train_auc = roc_auc_score(train_y, train_preds)\n",
    "    test_auc = roc_auc_score(test_y, test_preds)\n",
    "    accuracy = accuracy_score(test_y, predictions) \n",
    "    \n",
    "    return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n",
    "            'test auc': test_auc, 'train auc': train_auc\n",
    "           }\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 1000, 25),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 12, 1),\n",
    "    'm_child_weight': hp.quniform('m_child_weight', 1, 6, 1),\n",
    "    'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(.001), np.log(.3)),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', .5, 1, .1)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "xgb_hyperparams = fmin(fn = xgb_objective, \n",
    "                 max_evals = 150, \n",
    "                 trials = trials,\n",
    "                 algo = tpe.suggest,\n",
    "                 space = space\n",
    "                 )\n",
    "\n",
    "xgb_results = org_results(trials.trials, xgb_hyperparams, 'XGBoost')\n",
    "display(xgb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9bd14-04ee-4876-ab0d-94694fac51a3",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d18d8c-e63d-4a74-8154-42ba230a7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import early_stopping\n",
    "\n",
    "lgb_data = df.copy()\n",
    "lgb_dummy = pd.get_dummies(lgb_data[categorical], drop_first=True)\n",
    "lgb_data = pd.concat([lgb_dummy, lgb_data], axis=1)\n",
    "lgb_data.drop(columns = categorical, inplace=True)\n",
    "lgb_data.rename(columns={'Attrition_Yes': 'Attrition'}, inplace=True)\n",
    "y_df = lgb_data['Attrition'].reset_index(drop=True)\n",
    "x_df = lgb_data.drop(columns='Attrition')\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_df, y_df, test_size=0.20)\n",
    "\n",
    "def lgb_objective(space, early_stopping_rounds=50):\n",
    "    \n",
    "    lgbm = LGBMClassifier(\n",
    "        learning_rate = space['learning_rate'],\n",
    "        n_estimators= int(space['n_estimators']), \n",
    "        max_depth = int(space['max_depth']),\n",
    "        num_leaves = int(space['num_leaves']),\n",
    "        colsample_bytree = space['colsample_bytree'],\n",
    "        feature_fraction = space['feature_fraction'],\n",
    "        reg_lambda = space['reg_lambda'],\n",
    "        reg_alpha = space['reg_alpha'],\n",
    "        min_split_gain = space['min_split_gain'],\n",
    "        verbose = -1\n",
    "    )\n",
    "    \n",
    "    lgbm.fit(train_x, train_y, \n",
    "            eval_set = [(train_x, train_y), (test_x, test_y)],\n",
    "            eval_metric = 'auc',\n",
    "            callbacks = [early_stopping(stopping_rounds=early_stopping_rounds, verbose=False)])\n",
    "    \n",
    "    predictions = lgbm.predict(test_x)\n",
    "    test_preds = lgbm.predict_proba(test_x)[:,1]\n",
    "    train_preds = lgbm.predict_proba(train_x)[:,1]\n",
    "    \n",
    "    train_auc = roc_auc_score(train_y, train_preds)\n",
    "    test_auc = roc_auc_score(test_y, test_preds)\n",
    "    accuracy = accuracy_score(test_y, predictions)  \n",
    "    return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n",
    "            'test auc': test_auc, 'train auc': train_auc\n",
    "           }\n",
    "\n",
    "trials = Trials()\n",
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.3)),\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 1200, 25),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 15, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 10, 150, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0), \n",
    "    'feature_fraction': hp.uniform('feature_fraction', .3, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0.0001, 0.1)\n",
    "}\n",
    "\n",
    "lgb_hyperparams = fmin(fn = lgb_objective, \n",
    "                 max_evals = 150, \n",
    "                 trials = trials,\n",
    "                 algo = tpe.suggest,\n",
    "                 space = space\n",
    "                 )\n",
    "lgb_results = org_results(trials.trials, lgb_hyperparams, 'LightGBM')\n",
    "display(lgb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297de7cb-ee53-4fde-abb4-94df37cfc0e2",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92830b4f-8928-4ee0-a974-65d348b709cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbo_data = df.copy()\n",
    "\n",
    "for cat in categorical:\n",
    "    cbo_data[cat] = cbo_data[cat].astype('category').cat.codes\n",
    "\n",
    "y_df = cbo_data['Attrition'].reset_index(drop=True)\n",
    "x_df = cbo_data.drop(columns='Attrition')\n",
    "\n",
    "cboost_cat = categorical[1:]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_df, y_df, test_size=0.20)\n",
    "cat_dims = [train_x.columns.get_loc(name) for name in cboost_cat]     \n",
    "    \n",
    "def cat_objective(space, early_stopping_rounds=30):\n",
    "    \n",
    "    cboost = CatBoostClassifier(\n",
    "    eval_metric  = 'AUC', \n",
    "    learning_rate = space['learning_rate'],\n",
    "    iterations = space['iterations'],\n",
    "    depth = space['depth'],\n",
    "    l2_leaf_reg = space['l2_leaf_reg'],\n",
    "    border_count = space['border_count']\n",
    "    )\n",
    "    \n",
    "    cboost.fit(train_x, train_y, \n",
    "              eval_set = [(train_x, train_y), (test_x, test_y)],\n",
    "              early_stopping_rounds = early_stopping_rounds,\n",
    "              cat_features = cat_dims, \n",
    "              verbose = False)\n",
    "    \n",
    "    predictions = cboost.predict(test_x)\n",
    "    test_preds = cboost.predict_proba(test_x)[:,1]\n",
    "    train_preds = cboost.predict_proba(train_x)[:,1]    \n",
    "\n",
    "    train_auc = roc_auc_score(train_y, train_preds)\n",
    "    test_auc = roc_auc_score(test_y, test_preds)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    \n",
    "    return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n",
    "            'test auc': test_auc, 'train auc': train_auc}\n",
    "    \n",
    "trials = Trials()\n",
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.3)),\n",
    "    'iterations': hp.quniform('iterations', 25, 1000, 25),\n",
    "    'depth': hp.quniform('depth', 1, 16, 1),\n",
    "    'border_count': hp.quniform('border_count', 30, 220, 5), \n",
    "    'l2_leaf_reg': hp.quniform('l2_leaf_reg', 1, 10, 1)\n",
    "}\n",
    "\n",
    "cboost_hyperparams = fmin(fn = cat_objective, \n",
    "                 max_evals = 150, \n",
    "                 trials = trials,\n",
    "                 algo = tpe.suggest,\n",
    "                 space = space\n",
    "                 )\n",
    "\n",
    "cbo_results = org_results(trials.trials, cboost_hyperparams, 'CatBoost')\n",
    "display(cbo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac419fe2-4b84-4129-aea7-658f939556dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.DataFrame([xgb_results, lgb_results, cbo_results])\n",
    "display(final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
