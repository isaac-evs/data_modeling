{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1cdbeef-1d90-4b46-b4d7-baf7c797f9b5",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://glasswing.vc/wp-content/uploads/2023/10/16-CNNs.webp\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `sara.rodriguezr@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://glasswing.vc/wp-content/uploads/2023/10/16-CNNs.webp</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Entrenando un clasificador CNN</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a462d-1294-46b4-b766-b0e5560378d7",
   "metadata": {},
   "source": [
    "**MLP**\n",
    "\n",
    "Funcionan mejor para:\n",
    "- Datos tabulares (columnas de características)\n",
    "- Pequeños conjuntos de datos donde la estructura espacial es irrelevante\n",
    "- Tareas simples de clasificación o regresión PERO que los datos sean de alta dimensión o que haya relaciones no lineales complejas\n",
    "\n",
    "No son buenas para:\n",
    "- Imágenes\n",
    "- Video\n",
    "- Audio\n",
    "- Cualquier cosa con estructuras espaciales\n",
    "\n",
    "**CNN**\n",
    "\n",
    "Diseñadas específicamente para imágenes o cualquier cosa que tenga patrones espaciales locales.\n",
    "\n",
    "Funcionan mejor para:\n",
    "- Clasificacion de imágenes\n",
    "- Detección de objetos\n",
    "- Video\n",
    "\n",
    "Las CNN parten de tres supuestos:\n",
    "1. Existe estructura espacial\n",
    "\n",
    "Una CNN espera que los datos tengan forma (altura, largo, ancho) pero en un dataset tabular como: edad, ingresos, historial crediticio, ciudad. No existe ninguna estructura espacial. No tiene sentido aplicar un filtro 3x3 sobre [Edad, Ingresos, Ciudad]\n",
    "\n",
    "2. Esperan traslación invariance\n",
    "\n",
    "Una CNN aprende que un borde sigue siendo un borde, esté donde esté la imagen. Pero en los datos tabulares:\n",
    "- que \"edad\" esté en la columna 0 y \"ingresos\" en columna 1 NO significa que moverlos de sitio conserve el significado. \n",
    "\n",
    "No son buenas para:\n",
    "- Datos tabulares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdb303-2cee-40ee-91bf-43c4b011367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple as nt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "#Creamos un objeto con sus atributos\n",
    "Data = nt(\"Data\", \"x_train y_train x_valid y_valid x_test y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016ff6c-38ed-4de4-96f5-cda32bfd1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "data = Data(x_train, y_train, None, None, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1d753-70cc-4d57-b2e9-219c8b4a0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_labels = [\n",
    "    \"airplane\", \n",
    "    \"automobile\", \n",
    "    \"bird\", \n",
    "    \"cat\", \n",
    "    \"deer\", \n",
    "    \"dog\", \n",
    "    \"frog\", \n",
    "    \"horse\", \n",
    "    \"ship\", \n",
    "    \"truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7eecc4-86ea-4b6b-b2f5-af7e1e545705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(data):\n",
    "    images_to_show = 36\n",
    "    per_row = 12\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    for i in range(images_to_show):\n",
    "        pos = (i // per_row, ((i % per_row) + per_row) % per_row)\n",
    "        ax = plt.subplot2grid((int(images_to_show / per_row), per_row),\n",
    "                              pos, xticks=[], yticks=[])\n",
    "        ax.imshow(np.squeeze(data.x_train[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7b6ee-a590-4da5-b947-59f840c93d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos los datos\n",
    "visualize_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aef851-1a09-4a6f-82b2-394cdb1ff178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a trabjar solo con imagenes de Perros, Ranas y Caballos para que la carga computacional sea menor\n",
    "selected_classes = [5, 6, 7]\n",
    "\n",
    "train_mask = np.isin(y_train, selected_classes).flatten()\n",
    "x_train_filtered = x_train[train_mask]\n",
    "y_train_filtered = y_train[train_mask]\n",
    "\n",
    "test_mask = np.isin(y_test, selected_classes).flatten()\n",
    "x_test_filtered = x_test[test_mask]\n",
    "y_test_filtered = y_test[test_mask]\n",
    "\n",
    "filtered_data = Data(\n",
    "    x_train_filtered,\n",
    "    y_train_filtered,\n",
    "    None, None,\n",
    "    x_test_filtered,\n",
    "    y_test_filtered\n",
    ")\n",
    "\n",
    "visualize_data(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133d298-f39e-4151-8c91-3e696a197c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Están balanceadas nuestras clases?\n",
    "classes, counts = np.unique(filtered_data.y_train, return_counts=True)\n",
    "print(list(zip(classes, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e742e-4256-4cca-a00a-1a8507386224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva de aprendizaje\n",
    "def visualize_training(hist):\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['training', 'validation'], loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    # training vs validation loss\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6a3c4-1ce0-45d5-a232-ffe38e3f5a5e",
   "metadata": {},
   "source": [
    "**Preprocesamiento**\n",
    "\n",
    "Las imagenes son de 32x32 pixeles con valores entre 0 y 255 por cada pixel. \n",
    "Al hacerse demasiadas multiplicaciones vamos a dividir nuestros valores entre 255 de forma que los calculos no exploten en cada iteracion. \n",
    "\n",
    "RGB significa:\n",
    "- R = Red (Rojo)\n",
    "- G = Green (Verde)\n",
    "- B = Blue (Azul)\n",
    "\n",
    "Por ejemplo un pixel:\n",
    "[255, 0, 0] → rojo puro  \n",
    "[0, 255, 0] → verde puro  \n",
    "[0, 0, 255] → azul puro  \n",
    "[255, 255, 255] → blanco  \n",
    "[0, 0, 0] → negro\n",
    "\n",
    "Entonces un pixel puede tener 256 × 256 × 256 ≈ 16 millones de colores, por eso los modelos de deep learning normalizan los valores de 0 a 1. \n",
    "\n",
    "\n",
    "De la libreria de Keras vamos a usar la funcion \"to_categorical\" para hacer el one hot encoding a nuestras etiquetas. \n",
    "\n",
    "Vamos a seleccionar las primeras 5000 imagenes como train y las siguientes 5000 como validation\n",
    "\n",
    "Vamos a usar un set de validation para medir el accuracy durante el entrenamiento de la red yvamos a usar los datos del test para correr toda la red contra datos que no se han visto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a35011-536c-489a-aaf4-ecdf21755100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(data, categories):\n",
    "    x_train = data.x_train.astype(\"float32\") / 255\n",
    "    x_test = data.x_test.astype(\"float32\") / 255\n",
    "    y_train = to_categorical(data.y_train, categories)\n",
    "    y_test = to_categorical(data.y_test, categories)    \n",
    "    return Data(x_train[5000:], y_train[5000:],\n",
    "                x_train[:5000], y_train[:5000],\n",
    "                x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ceb56-6509-4e5d-bbbf-ae33dd20736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos los datos\n",
    "label_map = {5: 0, 6: 1, 7: 2}\n",
    "\n",
    "y_train_mapped = np.vectorize(label_map.get)(filtered_data.y_train)\n",
    "y_test_mapped  = np.vectorize(label_map.get)(filtered_data.y_test)\n",
    "\n",
    "filtered_data = Data(\n",
    "    filtered_data.x_train,\n",
    "    y_train_mapped,\n",
    "    filtered_data.x_valid,\n",
    "    filtered_data.y_valid,\n",
    "    filtered_data.x_test,\n",
    "    y_test_mapped\n",
    ")\n",
    "\n",
    "categories = len(np.unique(y_train_mapped))\n",
    "print(\"Shape de x_train pre-processing: \", filtered_data.x_train.shape)\n",
    "print(\"Shape de y_train pre-processing: \", filtered_data.y_train.shape)\n",
    "processed_data = preprocess(filtered_data, categories)\n",
    "print(\"Shape de x_train post-processing: \", processed_data.x_train.shape)\n",
    "print(\"Shape de y_train post-processing: \", processed_data.y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85eb81-9a81-4115-8e79-4b155f0436f9",
   "metadata": {},
   "source": [
    "## MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b760c-6ecf-4188-908f-275da70e7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(data, categories):\n",
    "    model = Sequential()\n",
    "    #En CIFAR una imagen tiene forma 32x32x3 --> 3072 valores, la mlp solo puede procesar vectores\n",
    "    model.add(Flatten(input_shape=data.x_train.shape[1:]))\n",
    "    model.add(Dense(1000, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(categories, activation=\"softmax\"))\n",
    "    \n",
    "    # Compilamos el modelo\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1af97-e284-432f-98d7-8950eb4018db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mlp\n",
    "mlp = build_mlp(processed_data, categories)\n",
    "print(\"Arquitectura de la MLP:\")\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593fe4c-cc9e-45e2-9fab-28f939616677",
   "metadata": {},
   "source": [
    "Son muchisimos parametros!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ca2ec-b4ad-45cf-a02b-aba5ae5b7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos el mlp\n",
    "hist_mlp = mlp.fit(processed_data.x_train, processed_data.y_train, batch_size=32, \n",
    "                   epochs=20, validation_data=(processed_data.x_valid,\n",
    "                                                processed_data.y_valid),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645871e-567a-4004-9f71-39456948f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training(hist_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6d343-df0b-484c-8f69-efa04d309b5c",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6ecde-27ae-4a7b-88de-991f98790a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97359c03-f402-4d47-bff5-64e923535ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(data, categories):\n",
    "    model = Sequential()\n",
    "    #algo comun que se hace es duplicar los fitlros en cada bloque\n",
    "    #padding = same hace que las dimensiones de las imagenes permanezcan controladas\n",
    "    model.add(Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"relu\",\n",
    "                     input_shape=data.x_train.shape[1:]))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=64, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(categories, activation=\"softmax\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1399296-80c4-45f3-bf89-73abc7879375",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = build_cnn(processed_data, categories)\n",
    "print(\"CNN architecture:\")\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b796c-fe97-4b8c-9758-8a8b075fca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the cnn\n",
    "hist_cnn = cnn.fit(processed_data.x_train, processed_data.y_train, batch_size=32, \n",
    "                   epochs=20, validation_data=(processed_data.x_valid, \n",
    "                                               processed_data.y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c285c14-3ff5-4785-ba18-043e10e529ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training(hist_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ac60c-74fb-484b-8995-7708c79dc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos los scores\n",
    "score_mlp = mlp.evaluate(processed_data.x_test, processed_data.y_test, verbose=0)\n",
    "score_cnn = cnn.evaluate(processed_data.x_test, processed_data.y_test, verbose=0)\n",
    "\n",
    "print(\"Accuracy mlp: {0:.2f}%\".format(score_mlp[1] * 100))\n",
    "print(\"Accuracy cnn: {0:.2f}%\".format(score_cnn[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21418f5b-7915-4613-bca7-fe1752a38c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0: \"dog\", 1: \"frog\", 2: \"horse\"}\n",
    "def visualize_predictions(model, data, class_names, num_images=20):\n",
    "    # Seleccionamos un subset aleatorio\n",
    "    idxs = np.random.choice(len(data.x_test), num_images, replace=False)\n",
    "    images = data.x_test[idxs]\n",
    "    true_labels = np.argmax(data.y_test[idxs], axis=1)\n",
    "\n",
    "    # Predicciones\n",
    "    preds = model.predict(images)\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt.subplot(4, 5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        true_c = true_labels[i]\n",
    "        pred_c = pred_labels[i]\n",
    "\n",
    "        # Color del texto\n",
    "        color = \"green\" if true_c == pred_c else \"red\"\n",
    "\n",
    "        plt.title(\n",
    "            f\"Pred: {class_names[pred_c]}\\nTrue: {class_names[true_c]}\",\n",
    "            color=color,\n",
    "            fontsize=10\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(cnn, processed_data, class_names, num_images=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
