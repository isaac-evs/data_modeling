{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52af96b9-3d18-4159-84d7-7deb7f8f44cc",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://miro.medium.com/0*uENSggbf2NdgFf9b.png\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `sara.rodriguezr@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://miro.medium.com/0*uENSggbf2NdgFf9b.png</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Calibración de probabilidades en clasificación</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5e458-ee26-4a6e-97cc-bd4eff80cac8",
   "metadata": {},
   "source": [
    "En clasificación, los algoritmos optimizan funciones y métricas de costos de todo o nada.\n",
    "\n",
    "Por ejemplo, la precisión sólo mide la frecuencia con la que acertamos y no dice nada sobre la confianza que tenemos en acertar, no mide \"distancias\" entre la realidad y la predición. \n",
    "\n",
    "En clasificación no tiene sentido decir que la distancia entre una foto de una avispa y una foto de una abeja es 5, al menos no de la misma manera que tiene sentido decir que la distancia entre el precio de un AirBnB de un dormitorio y el precio medio de otro AirBnB promedio de un dormitorio en el mismo vecindario es de $50.\n",
    "\n",
    "Como resultado, los algoritmos de clasificación tienden a tener pronósticos de predicción de probabilidad mucho más débiles y más sistemáticamente sesgados. Para casos en los que solo importa la clase asignada y no nos importa la confianza que tengamos en que esa probabilidad sea correcta, esto está bien. Si nos preocupamos por las probabilidades (por ejemplo, estamos compitiendo en una competencia de Kaggle cuya métrica es la pérdida logarítmica), este es un problema importante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76000ba3-7702-4cc5-8f97-5976c156e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay, calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876c7a3-dd8e-4141-9b59-0bef0978a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos dummies\n",
    "np.random.seed(42)\n",
    "X, y = make_classification(n_samples=10000, n_features=20, \n",
    "                           n_informative=2, n_redundant=2, \n",
    "                           n_classes=2, flip_y=0.1,\n",
    "                           random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0025f-aff1-4181-8869-58340085616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd48681-c5bb-4969-942e-55a039900d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos en entranmiento, validación(calibracion) y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_calib, X_test, y_calib, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2f9f0-6611-4677-aa60-10c36577df67",
   "metadata": {},
   "source": [
    "### Paso 1: Entrenamos modelo normalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2b0cb-e356-439a-9e22-59f01a96405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresion logistica\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "#Naive Bayes\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "#SVC\n",
    "model_svm = SVC(C=1.0, random_state=42, probability=True, kernel='linear')\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "#Random Forest\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dac253-3241-4a58-81db-4e5bf5eae26c",
   "metadata": {},
   "source": [
    "### Paso 2: Predecir probabilidades sin calibrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fb1e2-8c33-4dfc-92cc-3c2b73d88546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresion logistica\n",
    "probs_lr_uncal = model_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Naive Bayes\n",
    "probs_nb_uncal = model_nb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#SVM\n",
    "probs_svm_uncal = model_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#RF\n",
    "probs_rf_uncal = model_rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faedf14-8532-4158-82b9-a3c2652208d7",
   "metadata": {},
   "source": [
    "### Paso 3: Ajustar calibradores\n",
    "\n",
    "Importante: usar cv=\"prefit\" porque el modelo ya fue entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca963c31-58ae-40e8-8ad1-05af96c8f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresion logistica\n",
    "platt_lr = CalibratedClassifierCV(model_lr, method='sigmoid', cv='prefit')\n",
    "platt_lr.fit(X_calib, y_calib)\n",
    "\n",
    "iso_lr = CalibratedClassifierCV(model_lr, method='isotonic', cv='prefit')\n",
    "iso_lr.fit(X_calib, y_calib)\n",
    "\n",
    "#Naive Bayes\n",
    "platt_nb = CalibratedClassifierCV(model_nb, method='sigmoid', cv='prefit')\n",
    "platt_nb.fit(X_calib, y_calib)\n",
    "\n",
    "iso_nb = CalibratedClassifierCV(model_nb, method='isotonic', cv='prefit')\n",
    "iso_nb.fit(X_calib, y_calib)\n",
    "\n",
    "#SVC\n",
    "platt_svm = CalibratedClassifierCV(model_svm, method='sigmoid', cv='prefit')\n",
    "platt_svm.fit(X_calib, y_calib)\n",
    "\n",
    "iso_svm = CalibratedClassifierCV(model_svm, method='isotonic', cv='prefit')\n",
    "iso_svm.fit(X_calib, y_calib)\n",
    "\n",
    "#Random Forest\n",
    "platt_rf = CalibratedClassifierCV(model_rf, method='sigmoid', cv='prefit')\n",
    "platt_rf.fit(X_calib, y_calib)\n",
    "\n",
    "iso_rf = CalibratedClassifierCV(model_rf, method='isotonic', cv='prefit')\n",
    "iso_rf.fit(X_calib, y_calib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b3e1d-430c-43c1-b9e5-ff25613e9690",
   "metadata": {},
   "source": [
    "### Paso 4: Obtener probabilidades calibradas en el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5e3b3-1196-47da-9c73-44f878750bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresion logistica\n",
    "probs_lr_platt = platt_lr.predict_proba(X_test)[:, 1]\n",
    "probs_lr_iso = iso_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Naive Bayes\n",
    "probs_nb_platt = platt_nb.predict_proba(X_test)[:, 1]\n",
    "probs_nb_iso = iso_nb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#SVC\n",
    "probs_svm_platt = platt_svm.predict_proba(X_test)[:, 1]\n",
    "probs_svm_iso = iso_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#RF\n",
    "probs_rf_platt = platt_rf.predict_proba(X_test)[:, 1]\n",
    "probs_rf_iso = iso_rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bfee42-8030-464f-bbd9-246348945445",
   "metadata": {},
   "source": [
    "### Paso 5: Evaluar con Brier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9d457-b269-4b2e-a765-2b000a6da481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresion logistica\n",
    "print(\"------Regresion Logistica-----\")\n",
    "print(\"Brier sin calibrar:\", brier_score_loss(y_test, probs_lr_uncal))\n",
    "print(\"Brier Platt:\", brier_score_loss(y_test, probs_lr_platt))\n",
    "print(\"Brier Isotonic:\", brier_score_loss(y_test, probs_lr_iso))\n",
    "\n",
    "#Naive Bayes\n",
    "print(\"------Naive Bayes-----\")\n",
    "print(\"Brier sin calibrar:\", brier_score_loss(y_test, probs_nb_uncal))\n",
    "print(\"Brier Platt:\", brier_score_loss(y_test, probs_nb_platt))\n",
    "print(\"Brier Isotonic:\", brier_score_loss(y_test, probs_nb_iso))\n",
    "\n",
    "#SVC\n",
    "print(\"------SVC-----\")\n",
    "print(\"Brier sin calibrar:\", brier_score_loss(y_test, probs_svm_uncal))\n",
    "print(\"Brier Platt:\", brier_score_loss(y_test, probs_svm_platt))\n",
    "print(\"Brier Isotonic:\", brier_score_loss(y_test, probs_svm_iso))\n",
    "\n",
    "#RF\n",
    "print(\"------Random Forest-----\")\n",
    "print(\"Brier sin calibrar:\", brier_score_loss(y_test, probs_rf_uncal))\n",
    "print(\"Brier Platt:\", brier_score_loss(y_test, probs_rf_platt))\n",
    "print(\"Brier Isotonic:\", brier_score_loss(y_test, probs_rf_iso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3a5e1-56eb-4710-b184-de16e8423985",
   "metadata": {},
   "source": [
    "### Paso 6: Curvas de calibracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e8e87-e656-4ef0-bf17-376c76282a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curves(model_name, y_test, uncal, platt, iso):\n",
    "    \n",
    "    fr_uncal, pr_uncal = calibration_curve(y_test, uncal, n_bins=10)\n",
    "    fr_platt, pr_platt = calibration_curve(y_test, platt, n_bins=10)\n",
    "    fr_iso, pr_iso     = calibration_curve(y_test, iso, n_bins=10)\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(pr_uncal, fr_uncal, marker=\"o\", label=\"Sin calibrar\")\n",
    "    plt.plot(pr_platt, fr_platt, marker=\"o\", label=\"Platt scaling (sigmoid)\")\n",
    "    plt.plot(pr_iso,   fr_iso,   marker=\"o\", label=\"Isotonic regression\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "\n",
    "    plt.title(f\"Curva Calibracion - {model_name}\")\n",
    "    plt.xlabel(\"Probabilidad predicha\")\n",
    "    plt.ylabel(\"Frecuencia Observada\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f04fd-317e-466d-9123-d01875bd3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curves(\"Logistic Regression\", y_test, probs_lr_uncal, probs_lr_platt, probs_lr_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4adad3-5712-4e18-9c28-6c303d07c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curves(\"Naive Bayes\", y_test, probs_nb_uncal, probs_nb_platt, probs_nb_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac6f55-0d1c-4726-8a11-4d543e1066c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curves(\"SVM\", y_test, probs_svm_uncal, probs_svm_platt, probs_svm_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72ce0e-4a33-473b-a805-9068064b6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curves(\"Random Forest\", y_test, probs_rf_uncal, probs_rf_platt, probs_rf_iso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
