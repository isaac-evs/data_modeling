{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://static.wixstatic.com/media/aa08c3_4431b1d1a196452bb094eb2f08d4c4eb.png/v1/fit/w_620%2Ch_277%2Cal_c/file.png\" width=\"350px\" height=\"480px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodr√≠guez </Strong>\n",
    "- <Strong> A√±o </Strong>: 2025\n",
    "- \n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://static.wixstatic.com/media/aa08c3_4431b1d1a196452bb094eb2f08d4c4eb.png/v1/fit/w_620%2Ch_277%2Cal_c/file.png</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Regresi√≥n Lineal</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresi√≥n lineal es un m√©todo matem√°tico simple que se utiliza para comprender la relaci√≥n lineal entre una variable dependiente (lo que desea predecir) y una variable individual o un grupo de variables independientes (los factores que cree que afectan el valor de la variable dependiente).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¬øQu√© es la regresi√≥n?**\n",
    "\n",
    "La regresi√≥n muestra una l√≠nea o curva que pasa por todos los puntos de datos en un gr√°fico de tal manera que la distancia vertical entre los puntos de datos y la l√≠nea de regresi√≥n es la m√≠nima. \n",
    "\n",
    "Se usa principalmente para predicci√≥n pero tambi√©n es muy usada para determinar la relaci√≥n causa-efecto de las variables. \n",
    "\n",
    "Si hay una sola variable de entrada (x), dicha regresi√≥n lineal se denomina *regresi√≥n lineal simple*. Y si hay m√°s de una variable de entrada, dicha regresi√≥n lineal se denomina *regresi√≥n lineal m√∫ltiple*.\n",
    "\n",
    "## Cu√°ndo se recomienda usar la regresi√≥n lineal?\n",
    "\n",
    "1. Cuando la relaci√≥n entre las variables independientes  y la variable dependiente es aproximadamente lineal\n",
    "2. Cuando la distribuci√≥n de las variables de entrada siguen una distribuci√≥n normal\n",
    "3. Cuando los datos cumplen algunos supuestos\n",
    "    - Linealidad\n",
    "    - No Multicolinealidad\n",
    "    - Homoscedasticidad\n",
    "    - Normalidad en los residuales\n",
    "4. Incluso si los modelos m√°s complejos pudieran ajustarse un poco mejor, la regresi√≥n lineal es ideal cuando el conjunto de datos es ‚Äúexplicable‚Äù y las partes interesadas necesitan coeficientes para comprender la influencia de cada variable.\n",
    "5. Cuando no tienes muchos outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi√≥n Lineal M√∫ltiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Advertising.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset contiene informaci√≥n sobre el n√∫mero de anuncios que se hizo por diferentes medios (TV, Radio, Newspaper, Sales) y el total de ventas que hubo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vistazo a los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supuestos de la regresi√≥n lineal\n",
    "\n",
    "Cuando se cumplen las siguientes suposiciones, nos podemos asegurar que los resultados son confiables\n",
    "\n",
    "1. Linealidad\n",
    "2. No Multicolinealidad\n",
    "3. Homoscedasticidad\n",
    "4. Normalidad en los residuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observar la relacion entre las variables independientes y la dependiente\n",
    "p = sns.pairplot(data, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', height=7, aspect=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el resto de los supuestos requieren que realicemos la regresi√≥n antes de que podamos verificarlos. As√≠ que realicemos una regresi√≥n...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustamos un modelo lineal\n",
    "x = data.drop([\"Sales\"],axis=1)\n",
    "y = data.Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y,random_state = 0,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamos los datos los datos\n",
    "#Qu√© hacemos? normalizamos o estandarizamos?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos el modelo\n",
    "\n",
    "#Inicializamos el modelo\n",
    "reg = LinearRegression()\n",
    "\n",
    "#Entrenamos el modelo con los datos de entrenamiento\n",
    "reg.fit(X_train_scaled,y_train)\n",
    "\n",
    "#Predecimos con el modelo entrenado en el test\n",
    "y_pred = reg.predict(X_test_scaled)\n",
    "\n",
    "#Predecimos con el modelo entrenado en el train\n",
    "y_pred_train = reg.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficamos las prediccions vs los valores reales\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Valores Reales\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.title(\"Reales vs. Predicciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homoscedasticidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscamos patrones en los residuales. Si no hay patrones y est√°n de forma aleatoria graficados entonces es bueno\n",
    "residuales = y_test - y_pred\n",
    "p = sns.scatterplot(x=y_pred, y=residuales)\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Residuales')\n",
    "plt.ylim(-10,10)\n",
    "plt.xlim(0,26)\n",
    "p = sns.lineplot(x=[0,26],y=[0,0],color='blue')\n",
    "p = plt.title('Residuales vs Predicciones - revisando homoscedasticidad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalidad de los residuales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "sm.qqplot(residuales, line='45')\n",
    "plt.title(\"Q-Q Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Alternativamente, usamos un histograma\n",
    "sns.histplot(residuales, kde=True)\n",
    "plt.title(\"Histograma de Residuales\")\n",
    "plt.show()\n",
    "\n",
    "# Shapiro-Wilk test para la normalidad\n",
    "shapiro_test = stats.shapiro(residuales)\n",
    "print(f'Shapiro-Wilk Test p-value: {shapiro_test.pvalue}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza una prueba de Shapiro-Wilk para evaluar la normalidad de un conjunto de datos. La hip√≥tesis nula (ùêª0) para la prueba de Shapiro-Wilk es que los datos se distribuyen normalmente.\n",
    "\n",
    "La hip√≥tesis alternativa (ùêª1) es que los datos no se distribuyen normalmente.\n",
    "\n",
    "Este valor tan peque√±o obtenido nos dice que se rechaza la hip√≥tesis nula, por lo tanto los residuales no est√°n distribuidos normalmente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No multicolinealidad\n",
    "\n",
    "En regresi√≥n, la multicolinealidad se refiere al grado en que las variables independientes est√°n correlacionadas. \n",
    "\n",
    "La multicolinealidad afecta los coeficientes y los p-values, pero no influye en las predicciones, la precisi√≥n de las predicciones. \n",
    "\n",
    "**NOTA**: Si tu objetivo principal es hacer predicciones y no necesitas interpretar o entender el papel de cada variable independiente, no necesitas reducir la multicolinealidad severa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "p=sns.heatmap(X_train.corr(), annot=True,cmap='RdYlGn',square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correlaci√≥n dentro de las variables dependientes es lo que debemos buscar y evitar. \n",
    "\n",
    "Conclusion:\n",
    "\n",
    "\n",
    "En caso de que hubiera alguna, intentar√≠amos eliminar una de las variables correlacionadas dependiendo de cu√°l fuera m√°s importante para nuestro modelo de regresi√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qu√© tan preocupado deber√≠a estar si mi modelo no es perfecto, si mis residuales se ven un poquito mal?\n",
    "\n",
    "La respuesta es... Tu decides.\n",
    "\n",
    "Si est√°s publicando tu tesis en f√≠sica de part√≠culas, probablemente quieres asegurarse de que tu modelo sea lo m√°s preciso posible. Si est√°s tratando de realizar un an√°lisis r√°pido y sucio de las ventas del puesto de limonada de tu sobrino, un modelo no perfecto podr√≠a ser lo suficientemente bueno para responder cualquier pregunta que tengas (por ejemplo, si la \"temperatura\" parece afectar los \"ingresos\").\n",
    "\n",
    "La mayor√≠a de las veces, un modelo decente es mejor que ninguno. As√≠ que toma el modelo, intenta mejorarlo y luego decide si la precisi√≥n es lo suficientemente buena como para ser √∫til para tus prop√≥sitos.\n",
    "\n",
    "\n",
    "Aqu√≠ te dejo un poco de documentaci√≥n si quieres indagar en formas de c√≥mo mejorar los resultados de una regresi√≥n lineal:\n",
    "https://www.qualtrics.com/support/stats-iq/analyses/regression-guides/interpreting-residual-plots-improve-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluando el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R^2 test: {r2_score(y_test, y_pred)}\")\n",
    "print(f\"R^2 train: {r2_score(y_train, y_pred_train)}\")\n",
    "\n",
    "print(f\"RMSE test: {root_mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"RMSE train: {root_mean_squared_error(y_train, y_pred_train)}\")\n",
    "\n",
    "print(f\"MAE test: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MAE train: {mean_absolute_error(y_train, y_pred_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# KFold para regresion\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "#creamos un pipeline donde estandarizamos los datos de entrenamiento y luego aplicamos el modelo\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "scores = cross_val_score(pipeline, x, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "print(f\"  MSE scores: {scores*-1}\")\n",
    "print(f\"  Mean MSE: {(scores).mean()*-1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# curva de aprendizaje\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    estimator=pipeline,\n",
    "    X=x,\n",
    "    y=y,\n",
    "    cv=kf,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', label='Training score')\n",
    "plt.plot(train_sizes, val_mean, 'o-', label='Validation score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1)\n",
    "plt.title('Curva de aprendizaje')\n",
    "plt.xlabel('Set Size')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
